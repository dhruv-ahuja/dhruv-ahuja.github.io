<!doctype html><html class="dark light" lang=en><head><meta charset=UTF-8><meta content="IE=edge" http-equiv=X-UA-Compatible><meta content="width=device-width,initial-scale=1.0" name=viewport><meta content=https://dhruvahuja.me name=base><title>
            
                A Story of Optimizing Mongo DB Writes
            
        </title><meta content="A Story of Optimizing Mongo DB Writes" property=og:title><meta content="Optimizing bulk-inserts for 30,000+ MongoDB documents in a Python script." property=og:description><meta content="Optimizing bulk-inserts for 30,000+ MongoDB documents in a Python script." name=description><link href=https://dhruvahuja.me/icon/favicon.png rel=icon type=image/png><link href=https://dhruvahuja.me/fonts.css rel=stylesheet><link media="(prefers-color-scheme: dark)" href=/syntax-theme-dark.css rel=stylesheet><link media="(prefers-color-scheme: light)" href=/syntax-theme-light.css rel=stylesheet><script async data-goatcounter=https://dhruv-ahuja.goatcounter.com/count src=https://dhruvahuja.me/js/count.js></script><noscript><img src="https://dhruv-ahuja.goatcounter.com//count?p=/posts/optimizing-mongo-writes/&t=A Story of Optimizing Mongo DB Writes"></noscript><script defer src=https://dhruvahuja.me/js/codeblock.js></script><script defer src=https://dhruvahuja.me/js/toc.js></script><script src=https://dhruvahuja.me/js/note.js></script><script>MathJax = {
              tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
              }
            };</script><script async id=MathJax-script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link title="
    Dhruv Ahuja
" href=https://dhruvahuja.me/atom.xml rel=alternate type=application/atom+xml><link href=https://dhruvahuja.me/theme/light.css rel=stylesheet><link href=https://dhruvahuja.me/theme/dark.css id=darkModeStyle rel=stylesheet><script src=https://dhruvahuja.me/js/themetoggle.js></script><script>setTheme(getSavedTheme());</script><link href=https://dhruvahuja.me/main.css media=screen rel=stylesheet><link href=https://dhruvahuja.me/custom.css rel=stylesheet><link href=https://dhruvahuja.me/theme-sunset.css rel=stylesheet><script src="https://dhruvahuja.me/js/searchElasticlunr.min.js?h=3626c0ef99daa745b31e" defer></script><body><div class=left-content></div><div class=content><nav><div class=left-nav><a href=https://dhruvahuja.me>Dhruv Ahuja</a><div class=socials><a class=social href=mailto:dhruvahuja2k@gmail.com rel=noopener target=_blank> <img alt=email src=https://dhruvahuja.me/icons/social/email.svg> </a><a class=social href=https://www.linkedin.com/in/dhruvahuja2k/ rel=noopener target=_blank> <img alt=linkedin src=https://dhruvahuja.me/icons/social/linkedin.svg> </a><a class=social href=https://github.com/dhruv-ahuja/ rel=noopener target=_blank> <img alt=github src=https://dhruvahuja.me/icons/social/github.svg> </a></div></div><div class=right-nav><a href=https://dhruvahuja.me/posts style=margin-right:.5em>/posts</a><a href=https://dhruvahuja.me/projects style=margin-right:.5em>/projects</a><a href=https://dhruvahuja.me/oss style=margin-right:.5em>/oss</a><a href=https://dhruvahuja.me/tags style=margin-right:.5em>/tags</a><button title="$SHORTCUT to open search" class=search-button id=search-button><img alt=Search class=search-icon src=https://dhruvahuja.me/icons/search.svg></button><div class="search-modal js" aria-labelledby=modalTitle id=searchModal role=dialog><div id=modal-content><h1 class=page-header id=modalTitle>Search</h1><div id=searchBar><input aria-controls=results-container aria-expanded=false autocomplete=off id=searchInput placeholder=Search... role=combobox spellcheck=false><button title="Clear search" class=clear-button id=clear-search><svg viewbox="0 -960 960 960" xmlns=http://www.w3.org/2000/svg><path d="m256-200-56-56 224-224-224-224 56-56 224 224 224-224 56 56-224 224 224 224-56 56-224-224-224 224Z"/></svg></button></div><div id=results-container><div id=results-info><span id=zero_results style=display:none>No results</span><span id=one_result style=display:none>1 result</span><span id=many_results style=display:none>$NUMBER results</span></div><div id=results role=listbox></div></div></div></div><a onclick="toggleTheme(); event.preventDefault();" href=# id=dark-mode-toggle> <img alt=Light id=sun-icon src=https://dhruvahuja.me/icons/sun.svg style=filter:invert()> <img alt=Dark id=moon-icon src=https://dhruvahuja.me/icons/moon.svg> </a><script>updateItemToggleTheme()</script></div></nav><div data-selector="main article p" class=visible-element-observer-root><main><article><div class=title><div class=page-header>A Story of Optimizing Mongo DB Writes</div><div class=meta>Posted on <time>2024-05-21</time><span class=tags-label>::</span><span class=tags> <a class=post-tag href=https://dhruvahuja.me/tags/database/>database</a> <a class=post-tag href=https://dhruvahuja.me/tags/optimization/>optimization</a> <a class=post-tag href=https://dhruvahuja.me/tags/python/>python</a> </span></div></div><section class=body><h2 id=introduction>Introduction</h2><p>I am developing an application for the game Path of Exile, that will predict item prices based on the item quantity and the item price history throughout the season. It is a straightforward implementation that updates the prices for items at a fixed frequency, and requires items and their categories to be pre-populated in the database.<p>I am running my MongoDB server on the Atlas Free Tier, hosted on AWS.<p>The core flow is as follows: there are several categories for whom we already have general information prepared, we first create <code>ItemCategory</code>  documents with this information for each category. Then we fetch data for all items belonging to that category. The <a href=https://poe.ninja rel=noopener target=_blank title=https://poe.ninja>poe.ninja</a> website caches its API responses and we’re able to quickly fetch the desired data even with relatively large responses. We initially made all these API calls in a loop, and the whole process was quite smooth as the response time is always quick. Upon getting the data and parsing each entity in the response array into Pydantic models, we then map the data in the form <code>&LTcategory_name: item_data></code> where <code>item_data</code> is the list of items we fetched from the API. Do keep in mind that this flow will change as optimize the script down the line.<h2 id=pydantic-its-usage-here>Pydantic & Its Usage Here  </h2><p>We create either <code>CurrencyItemEntity</code> or  <code>ItemEntity</code>  Pydantic model instances for each entity in API responses, based on whether it belongs to <code>Currency</code> or the other <code>Item</code> type, as items in the <code>Currency</code> category have a separate API response schema. Pydantic helps maintain data integrity and validates the response data, making it easier to deal with potentially unstructured third-party data (although the APIs in this case are very consistent). There would definitely be an additional overhead for parsing the item data into a Pydantic model instance for each entity, but being able to enforce schema for third-party data in this case, and getting consistent type hint support is well worth it. Its performance has also been vastly improved with the version 2.0 release that happened late last year.<h2 id=the-naive-approach-single-insertions>The Naive Approach: Single Insertions</h2><p>The code for the naive approach and the first iteration of the script is <a href=https://github.com/dhruv-ahuja/backend_burger/blob/c7337e97601e72dd80979ba9cf7ab25111283237/src/scripts/poe_initial.py rel=noopener target=_blank title=https://github.com/dhruv-ahuja/backend_burger/blob/c7337e97601e72dd80979ba9cf7ab25111283237/src/scripts/poe_initial.py>available here</a>. Here we are iterating over all categories, getting their response data and mapping them into the hashmap with <code>category name</code> as key, and the <code>data array</code> as value. It does not take much time to gather data for 31,000+ items, as mentioned above due to the quick API responses.<p>Calling <code>save_item_data</code>, It takes us an average of <strong>1216 seconds</strong> or <strong>20 minutes 16 seconds</strong> to parse each entity’s data, create and insert <code>Item</code> document instances and save them to the database one-by-one. I think this time is acceptable since the script meant to be run rarely, however it is practically very slow and not convenient. This makes extending the script or re-running it a chore. I am also interested in knowing how much time we can shave off from this, especially since there is a very simple optimization available. Memory usage for this approach would be high too, since we’re loading all item data entities in memory and have two objects for each entity. We will look into memory management after improving the execution time.<p>Each save call requires network round trips between the app and the database, and database processing time. These accumulate rapidly as we save a large number of documents one-by-one.<h2 id=the-good-approach-bulk-insertions>The Good Approach: Bulk Insertions</h2><p>The modified script using approach is <a href=https://github.com/dhruv-ahuja/backend_burger/blob/d88fecd8a44626445f56131544307abee500a98a/src/scripts/poe_initial.py rel=noopener target=_blank title=https://github.com/dhruv-ahuja/backend_burger/blob/d88fecd8a44626445f56131544307abee500a98a/src/scripts/poe_initial.py>available here</a>. I found using <code>insertMany</code> for bulk-inserts the most common and the most impactful approach, when I looked for improvement advice. Pushing all DB instances to an array and bulk-inserting them all at once, took us just ~10.7 seconds!  This is an incredible improvement and should be the first choice if you need to insert multiple documents.<p>The problem here is the memory usage, which peaks at roughly 350MB and only drops towards the end of the script, where we see memory being released.<p><img alt="Bulk-Inserts Memory Consumption" src=/images/mongodb_writes/poe_script_memory_usage.png><p>This can be verified by simply restricting the maximum length of the <code>item_data</code> array to 10,000, which would restrict the number of accessed item data records of the <code>BaseType</code> category, which has contains much more items. Making this change reduces the peak memory usage to ~285MB.<p><img alt="Bulk-Inserts Memory Consumption, Restricted Object Count" src=/images/mongodb_writes/poe_script_limited_memory_usage.png><p>We can make one more improvement which will reduce both the memory usage and execution time, but requires a significant code refactor.<h2 id=the-better-approach-producer-consumer-pattern>The Better Approach: Producer-Consumer Pattern</h2><p>The mostly overhauled script using this approach is <a href=https://github.com/dhruv-ahuja/backend_burger/blob/bb50fbac45fa38df28f48753690655fb2ee901b2/src/scripts/poe_initial.py rel=noopener target=_blank title=https://github.com/dhruv-ahuja/backend_burger/blob/bb50fbac45fa38df28f48753690655fb2ee901b2/src/scripts/poe_initial.py>available here</a>. We rewrote the main functions, moved API calls to their own functions, added more logging statements, handled errors and wrapped the async functions into async <code>Task</code>s. These pass data using dedicated <code>Queue</code>s and run until they get the termination signals using sentinel values.<p>Implementing Async Producer and Consumers means we now process information faster, by using different async tasks to concurrently get API data, parse that data, and save documents in bulk in the database.<p>This coordination allows us to reduce the time taken further to about 9 seconds, and all the tasks finish execution almost one after the other. This is an improvement of about 1.7 seconds over the bulk-insert implementation. We also witness a big drop in memory usage, with the peak memory usage being ~271MB, or an improvement of ~ 22.6% over the previous consumption of 350MB. These are fantastic results, in my opinion.<p><img alt="Optimal Approach Memory Consumption" src=/images/mongodb_writes/poe_script_async.png><h2 id=conclusion>Conclusion</h2><p>This was a journey where I got hands-on with some general performance improvements for database writes and also implemented the common but very effective Producer-Consumer design pattern. I am sure that there are things that I missed and certain aspects that can be handled better, I’ll be keeping an eye out for any improvements.<p>It was a great learning and experimental experience for me, and I hope that this made a good read for you. Please do not hesitate to <a href=mailto:dhruvahuja2k@gmail.com/ title=mailto:dhruvahuja2k@gmail.com/>email me</a> if you wish to discuss anything. I will be adding comments functionality to the site soon.</section></article></main></div></div><div class=right-content><div class=toc><div class=heading>Table of Contents</div><ul class=toc-list><li class=parent><a href=https://dhruvahuja.me/posts/optimizing-mongo-writes/#introduction>Introduction</a><li class=parent><a href=https://dhruvahuja.me/posts/optimizing-mongo-writes/#pydantic-its-usage-here>Pydantic & Its Usage Here  </a><li class=parent><a href=https://dhruvahuja.me/posts/optimizing-mongo-writes/#the-naive-approach-single-insertions>The Naive Approach: Single Insertions</a><li class=parent><a href=https://dhruvahuja.me/posts/optimizing-mongo-writes/#the-good-approach-bulk-insertions>The Good Approach: Bulk Insertions</a><li class=parent><a href=https://dhruvahuja.me/posts/optimizing-mongo-writes/#the-better-approach-producer-consumer-pattern>The Better Approach: Producer-Consumer Pattern</a><li class=parent><a href=https://dhruvahuja.me/posts/optimizing-mongo-writes/#conclusion>Conclusion</a></ul></div></div>